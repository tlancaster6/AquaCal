{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration Diagnostics and Visualization\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-username/aquacal/blob/main/docs/tutorials/02_diagnostics.ipynb)\n",
    "\n",
    "This tutorial shows you how to interpret calibration quality and diagnose issues using reprojection error analysis, parameter convergence plots, and 3D rig visualization.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Understanding reprojection error metrics and what good values look like\n",
    "- Spatial error analysis across the image plane\n",
    "- Parameter convergence and interface distance estimation\n",
    "- 3D visualization of camera rig geometry\n",
    "- Common failure modes and how to fix them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data source toggle: choose which dataset to use\n",
    "DATASET = \"small\"  # Options: \"small\" (fast, included), \"medium\", \"large\"\n",
    "\n",
    "# For Google Colab: uncomment to install aquacal\n",
    "# !pip install aquacal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from aquacal.config.schema import InterfaceParams\n",
    "from aquacal.core.board import BoardGeometry\n",
    "from aquacal.datasets import generate_synthetic_rig\n",
    "from tests.synthetic.ground_truth import generate_synthetic_detections\n",
    "\n",
    "print(f\"Loading {DATASET} dataset...\")\n",
    "\n",
    "# Generate synthetic scenario with known ground truth\n",
    "scenario = generate_synthetic_rig(DATASET)\n",
    "print(f\"  {len(scenario.intrinsics)} cameras\")\n",
    "print(f\"  {len(scenario.board_poses)} frames\")\n",
    "print(f\"  {scenario.noise_std}px detection noise\")\n",
    "\n",
    "# Create board geometry\n",
    "board = BoardGeometry(scenario.board_config)\n",
    "\n",
    "# Generate synthetic detections\n",
    "detections = generate_synthetic_detections(\n",
    "    intrinsics=scenario.intrinsics,\n",
    "    extrinsics=scenario.extrinsics,\n",
    "    water_zs=scenario.water_zs,\n",
    "    board=board,\n",
    "    board_poses=scenario.board_poses,\n",
    "    noise_std=scenario.noise_std,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(\"\\nRunning calibration pipeline...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run calibration (Stages 2-4)\nfrom aquacal.calibration.extrinsics import build_pose_graph, estimate_extrinsics\nfrom aquacal.calibration.interface_estimation import optimize_interface\nfrom aquacal.calibration.refinement import joint_refinement\nfrom aquacal.config.schema import (\n    CalibrationMetadata,\n    CalibrationResult,\n    CameraCalibration,\n    DiagnosticsData,\n)\nfrom aquacal.validation.reprojection import compute_reprojection_errors\n\nreference_camera = \"cam0\"\ninterface_normal = np.array([0.0, 0.0, -1.0], dtype=np.float64)\n\n# Stage 2: Extrinsic initialization\nprint(\"  Stage 2: Extrinsic initialization...\")\npose_graph = build_pose_graph(detections, min_cameras=2)\ninitial_extrinsics = estimate_extrinsics(\n    pose_graph, scenario.intrinsics, board, reference_camera\n)\n\n# Stage 3: Joint refractive optimization\nprint(\"  Stage 3: Joint refractive optimization...\")\nopt_extrinsics, opt_distances, opt_poses, rms = optimize_interface(\n    detections=detections,\n    intrinsics=scenario.intrinsics,\n    initial_extrinsics=initial_extrinsics,\n    board=board,\n    reference_camera=reference_camera,\n    interface_normal=interface_normal,\n    n_air=1.0,\n    n_water=1.333,\n    loss=\"huber\",\n    loss_scale=1.0,\n    min_corners=4,\n)\n\n# Stage 4: Intrinsic refinement\nprint(\"  Stage 4: Intrinsic refinement...\")\nstage3_result = (opt_extrinsics, opt_distances, opt_poses, rms)\nopt_extrinsics, opt_distances, opt_poses, opt_intrinsics, rms = joint_refinement(\n    stage3_result=stage3_result,\n    detections=detections,\n    intrinsics=scenario.intrinsics,\n    board=board,\n    reference_camera=reference_camera,\n    refine_intrinsics=True,\n    interface_normal=interface_normal,\n    n_air=1.0,\n    n_water=1.333,\n    loss=\"huber\",\n    loss_scale=1.0,\n    min_corners=4,\n)\n\n# Build CalibrationResult\ncameras = {}\nfor cam_name in scenario.intrinsics:\n    cameras[cam_name] = CameraCalibration(\n        name=cam_name,\n        intrinsics=opt_intrinsics[cam_name],\n        extrinsics=opt_extrinsics[cam_name],\n        water_z=opt_distances[cam_name],\n    )\n\ninterface_params = InterfaceParams(\n    normal=interface_normal,\n    n_air=1.0,\n    n_water=1.333,\n)\n\n# Compute per-camera RMS errors\n\nper_camera_rms = {}\nfor cam_name in cameras:\n    cam_errors = compute_reprojection_errors(\n        calibration=cameras[cam_name],\n        interface_params=interface_params,\n        detections=detections,\n        board=board,\n    )\n    per_camera_rms[cam_name] = np.sqrt(np.mean(cam_errors**2))\n\ndiagnostics = DiagnosticsData(\n    reprojection_error_rms=rms,\n    reprojection_error_per_camera=per_camera_rms,\n    validation_3d_error_mean=0.0,\n    validation_3d_error_std=0.0,\n)\n\nmetadata = CalibrationMetadata(\n    calibration_date=\"synthetic\",\n    software_version=\"test\",\n    config_hash=\"synthetic\",\n    num_frames_used=len(opt_poses),\n    num_frames_holdout=0,\n)\n\nresult = CalibrationResult(\n    cameras=cameras,\n    interface=interface_params,\n    board=scenario.board_config,\n    diagnostics=diagnostics,\n    metadata=metadata,\n)\n\nprint(\"\\nCalibration complete!\")\nprint(f\"  Overall RMS: {result.diagnostics.reprojection_error_rms:.3f} px\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reprojection Error Analysis\n",
    "\n",
    "Reprojection error measures how well the calibrated model predicts the observed corner positions. Low values (<1 px for good detections) indicate accurate calibration.\n",
    "\n",
    "**What good values look like:**\n",
    "- Overall RMS: < 1.0 px (excellent), < 2.0 px (good)\n",
    "- Per-camera variation: cameras should have similar RMS values\n",
    "- Spatial uniformity: errors should be distributed evenly across the image plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-camera RMS error bar chart\n",
    "camera_names = sorted(result.cameras.keys())\n",
    "rms_values = [\n",
    "    result.diagnostics.reprojection_error_per_camera[cam] for cam in camera_names\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.bar(camera_names, rms_values, color=\"steelblue\", alpha=0.8)\n",
    "ax.axhline(\n",
    "    result.diagnostics.reprojection_error_rms,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"Overall RMS\",\n",
    ")\n",
    "ax.set_xlabel(\"Camera\")\n",
    "ax.set_ylabel(\"RMS Reprojection Error (px)\")\n",
    "ax.set_title(\"Per-Camera Reprojection Error\")\n",
    "ax.legend()\n",
    "ax.grid(axis=\"y\", alpha=0.3)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\n",
    "    \"\\n⚠️  **Warning:** High error in one camera often indicates poor intrinsics or insufficient board observations for that camera.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all reprojection errors for distribution analysis\n",
    "all_errors = []\n",
    "spatial_errors = []  # For spatial heatmap: (u, v, error)\n",
    "\n",
    "for cam_name in camera_names:\n",
    "    cam = result.cameras[cam_name]\n",
    "    errors = compute_reprojection_errors(\n",
    "        calibration=cam,\n",
    "        interface_params=result.interface,\n",
    "        detections=detections,\n",
    "        board=board,\n",
    "    )\n",
    "\n",
    "    # Compute error magnitudes\n",
    "    error_mags = np.linalg.norm(errors, axis=1)\n",
    "    all_errors.extend(error_mags)\n",
    "\n",
    "    # Store spatial data (u, v, error) for first camera only (for heatmap demo)\n",
    "    if cam_name == camera_names[0]:\n",
    "        for frame_idx, frame_det in detections.frames.items():\n",
    "            if cam_name in frame_det.detections:\n",
    "                obs = frame_det.detections[cam_name]\n",
    "                for i in range(len(obs.corner_ids)):\n",
    "                    u, v = obs.image_points[i]\n",
    "                    spatial_errors.append(\n",
    "                        (u, v, error_mags[i] if i < len(error_mags) else 0)\n",
    "                    )\n",
    "\n",
    "# Histogram of error distribution\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.hist(all_errors, bins=30, color=\"steelblue\", alpha=0.7, edgecolor=\"black\")\n",
    "ax.axvline(\n",
    "    np.mean(all_errors),\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Mean: {np.mean(all_errors):.2f} px\",\n",
    ")\n",
    "ax.set_xlabel(\"Reprojection Error (px)\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_title(\"Reprojection Error Distribution (All Cameras)\")\n",
    "ax.legend()\n",
    "ax.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"Error statistics:\")\n",
    "print(f\"  Mean: {np.mean(all_errors):.3f} px\")\n",
    "print(f\"  Median: {np.median(all_errors):.3f} px\")\n",
    "print(f\"  95th percentile: {np.percentile(all_errors, 95):.3f} px\")\n",
    "print(f\"  Max: {np.max(all_errors):.3f} px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial error heatmap (for first camera as example)\n",
    "if len(spatial_errors) > 0:\n",
    "    spatial_errors = np.array(spatial_errors)\n",
    "    u_coords = spatial_errors[:, 0]\n",
    "    v_coords = spatial_errors[:, 1]\n",
    "    errors = spatial_errors[:, 2]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    scatter = ax.scatter(\n",
    "        u_coords,\n",
    "        v_coords,\n",
    "        c=errors,\n",
    "        cmap=\"hot\",\n",
    "        s=50,\n",
    "        alpha=0.6,\n",
    "        edgecolors=\"black\",\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "    ax.set_xlabel(\"u (pixels)\")\n",
    "    ax.set_ylabel(\"v (pixels)\")\n",
    "    ax.set_title(f\"Spatial Error Distribution ({camera_names[0]})\")\n",
    "    ax.invert_yaxis()  # Image coordinate convention\n",
    "    ax.set_aspect(\"equal\")\n",
    "    cbar = plt.colorbar(scatter, ax=ax)\n",
    "    cbar.set_label(\"Reprojection Error (px)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    print(\"\\nSpatial error heatmap shows error distribution across the image plane.\")\n",
    "    print(\n",
    "        \"Clusters of high error may indicate distortion modeling issues or board pose degeneracies.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Convergence\n",
    "\n",
    "For synthetic data, we can compare estimated parameters to ground truth. This shows how well the optimization converged to the true values.\n",
    "\n",
    "**Interface distance** is the Z-coordinate of the water surface in world frame (meters). All cameras should estimate similar values after optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare estimated interface distances to ground truth\n",
    "estimated_distances = [result.cameras[cam].water_z for cam in camera_names]\n",
    "gt_distances = [scenario.water_zs[cam] for cam in camera_names]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "x = np.arange(len(camera_names))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(\n",
    "    x - width / 2,\n",
    "    estimated_distances,\n",
    "    width,\n",
    "    label=\"Estimated\",\n",
    "    color=\"steelblue\",\n",
    "    alpha=0.8,\n",
    ")\n",
    "ax.bar(\n",
    "    x + width / 2, gt_distances, width, label=\"Ground Truth\", color=\"orange\", alpha=0.8\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Camera\")\n",
    "ax.set_ylabel(\"Interface Distance (m)\")\n",
    "ax.set_title(\"Interface Distance Recovery\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(camera_names, rotation=45, ha=\"right\")\n",
    "ax.legend()\n",
    "ax.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "mean_error = np.mean(\n",
    "    [abs(est - gt) for est, gt in zip(estimated_distances, gt_distances)]\n",
    ")\n",
    "print(f\"\\nMean absolute interface distance error: {mean_error * 1000:.2f} mm\")\n",
    "print(\n",
    "    \"\\n⚠️  **Warning:** If interface distance diverges or oscillates, the initial estimate may be too far from truth. Try providing explicit initial_distances in config.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare camera positions (Z-coordinate) to ground truth\n",
    "estimated_z = [result.cameras[cam].extrinsics.C[2] for cam in camera_names]\n",
    "gt_z = [scenario.extrinsics[cam].C[2] for cam in camera_names]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "x = np.arange(len(camera_names))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(\n",
    "    x - width / 2, estimated_z, width, label=\"Estimated\", color=\"steelblue\", alpha=0.8\n",
    ")\n",
    "ax.bar(x + width / 2, gt_z, width, label=\"Ground Truth\", color=\"orange\", alpha=0.8)\n",
    "\n",
    "ax.set_xlabel(\"Camera\")\n",
    "ax.set_ylabel(\"Camera Z Position (m)\")\n",
    "ax.set_title(\"Camera Z Position Recovery\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(camera_names, rotation=45, ha=\"right\")\n",
    "ax.legend()\n",
    "ax.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "z_errors = [abs(est - gt) * 1000 for est, gt in zip(estimated_z, gt_z)]\n",
    "print(f\"\\nCamera Z position errors (mm): {[f'{e:.2f}' for e in z_errors]}\")\n",
    "print(f\"Mean: {np.mean(z_errors):.2f} mm, Max: {np.max(z_errors):.2f} mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Rig Visualization\n",
    "\n",
    "Visualizing the camera rig in 3D helps verify that the estimated geometry is physically plausible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D plot of camera rig\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Top view\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "for cam_name in camera_names:\n",
    "    C_est = result.cameras[cam_name].extrinsics.C\n",
    "    C_gt = scenario.extrinsics[cam_name].C\n",
    "    ax1.scatter(\n",
    "        C_est[0], C_est[1], marker=\"o\", s=100, label=f\"{cam_name} (est)\", alpha=0.7\n",
    "    )\n",
    "    ax1.scatter(\n",
    "        C_gt[0], C_gt[1], marker=\"x\", s=100, label=f\"{cam_name} (gt)\", alpha=0.7\n",
    "    )\n",
    "    ax1.plot([C_est[0], C_gt[0]], [C_est[1], C_gt[1]], \"k--\", alpha=0.3)\n",
    "\n",
    "ax1.set_xlabel(\"X (m)\")\n",
    "ax1.set_ylabel(\"Y (m)\")\n",
    "ax1.set_title(\"Top View (XY Plane)\")\n",
    "ax1.set_aspect(\"equal\")\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Side view (XZ)\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "for cam_name in camera_names:\n",
    "    C_est = result.cameras[cam_name].extrinsics.C\n",
    "    C_gt = scenario.extrinsics[cam_name].C\n",
    "    ax2.scatter(C_est[0], C_est[2], marker=\"o\", s=100, alpha=0.7)\n",
    "    ax2.scatter(C_gt[0], C_gt[2], marker=\"x\", s=100, alpha=0.7)\n",
    "    ax2.plot([C_est[0], C_gt[0]], [C_est[2], C_gt[2]], \"k--\", alpha=0.3)\n",
    "\n",
    "# Water surface (average interface distance)\n",
    "water_z = np.mean(estimated_distances)\n",
    "ax2.axhline(water_z, color=\"blue\", linestyle=\"--\", alpha=0.5, label=\"Water surface\")\n",
    "\n",
    "ax2.set_xlabel(\"X (m)\")\n",
    "ax2.set_ylabel(\"Z (m)\")\n",
    "ax2.set_title(\"Side View (XZ Plane)\")\n",
    "ax2.set_aspect(\"equal\")\n",
    "ax2.grid(alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "# 3D view\n",
    "ax3 = fig.add_subplot(2, 2, 3, projection=\"3d\")\n",
    "for cam_name in camera_names:\n",
    "    C_est = result.cameras[cam_name].extrinsics.C\n",
    "    C_gt = scenario.extrinsics[cam_name].C\n",
    "    ax3.scatter(\n",
    "        C_est[0],\n",
    "        C_est[1],\n",
    "        C_est[2],\n",
    "        marker=\"o\",\n",
    "        s=100,\n",
    "        label=f\"{cam_name} (est)\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    ax3.scatter(C_gt[0], C_gt[1], C_gt[2], marker=\"x\", s=100, alpha=0.7)\n",
    "\n",
    "# Water surface plane\n",
    "xlim = ax3.get_xlim()\n",
    "ylim = ax3.get_ylim()\n",
    "xx, yy = np.meshgrid(xlim, ylim)\n",
    "zz = np.full_like(xx, water_z)\n",
    "ax3.plot_surface(xx, yy, zz, color=\"blue\", alpha=0.2)\n",
    "\n",
    "ax3.set_xlabel(\"X (m)\")\n",
    "ax3.set_ylabel(\"Y (m)\")\n",
    "ax3.set_zlabel(\"Z (m)\")\n",
    "ax3.set_title(\"3D View\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nBlue circles: estimated camera positions\")\n",
    "print(\"Orange crosses: ground truth camera positions\")\n",
    "print(\"Dashed lines: position errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Metrics\n",
    "\n",
    "3D reconstruction error: triangulate known board corners and compare to true spacing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate 3D reconstruction accuracy\n",
    "from aquacal.validation.reconstruction import compute_3d_distance_errors\n",
    "\n",
    "dist_errors = compute_3d_distance_errors(\n",
    "    calibration=result,\n",
    "    detections=detections,\n",
    "    board=board,\n",
    "    include_per_pair=False,\n",
    "    include_spatial=True,\n",
    ")\n",
    "\n",
    "print(\"\\n3D Reconstruction Quality:\")\n",
    "print(f\"  Signed mean error: {dist_errors.signed_mean * 1000:.3f} mm\")\n",
    "print(f\"  RMSE: {dist_errors.rmse * 1000:.3f} mm\")\n",
    "print(\n",
    "    f\"  Scale factor (measured/true): {1.0 + dist_errors.signed_mean / board.config.square_size:.6f}\"\n",
    ")\n",
    "print(f\"  Number of comparisons: {dist_errors.num_comparisons}\")\n",
    "\n",
    "# Histogram of distance errors\n",
    "if dist_errors.spatial is not None:\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.hist(\n",
    "        dist_errors.spatial.signed_errors * 1000,\n",
    "        bins=30,\n",
    "        color=\"steelblue\",\n",
    "        alpha=0.7,\n",
    "        edgecolor=\"black\",\n",
    "    )\n",
    "    ax.axvline(0, color=\"black\", linestyle=\"--\", alpha=0.5)\n",
    "    ax.axvline(\n",
    "        dist_errors.signed_mean * 1000,\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Mean: {dist_errors.signed_mean * 1000:.2f} mm\",\n",
    "    )\n",
    "    ax.set_xlabel(\"Signed Distance Error (mm)\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.set_title(\"3D Reconstruction Error Distribution\")\n",
    "    ax.legend()\n",
    "    ax.grid(axis=\"y\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Issues Checklist\n",
    "\n",
    "| Symptom | Likely Cause | Fix |\n",
    "|---------|-------------|-----|\n",
    "| High error for one camera | Poor intrinsic calibration quality | Re-calibrate intrinsics with more frames, check for motion blur |\n",
    "| High error in image corners | Distortion model insufficient | Try rational model (8 coefficients) or fisheye model |\n",
    "| Interface distance not converging | Initial estimate too far from truth | Provide better `initial_water_zs` in config |\n",
    "| Interface distances differ between cameras | Degenerate board poses | Ensure board is visible at varied angles and depths |\n",
    "| Spatial error clusters | Board pose degeneracies | Add more frames with board at different orientations |\n",
    "| High 3D reconstruction error | Systematic bias in parameters | Check that n_water is correct for your water type |\n",
    "| Reprojection < 1px but 3D error high | Overfitting to 2D, wrong geometry | Verify interface distance initialization, add validation frames |\n",
    "\n",
    "---\n",
    "\n",
    "**Next steps:**\n",
    "- If errors are high: review intrinsic calibration, add more extrinsic frames\n",
    "- If parameters don't converge: improve initialization estimates\n",
    "- If everything looks good: proceed to full dataset calibration!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
