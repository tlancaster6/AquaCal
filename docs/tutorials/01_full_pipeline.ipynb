{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Pipeline Tutorial",
    "",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tlancaster6/AquaCal/blob/main/docs/tutorials/01_full_pipeline.ipynb)",
    "",
    "This tutorial demonstrates the complete AquaCal calibration pipeline from start to finish. You'll learn how to:",
    "",
    "- Load synthetic or real calibration data",
    "- Run all four calibration stages",
    "- Visualize camera rig geometry and calibration quality",
    "- Validate results and interpret metrics",
    "",
    "**Prerequisites:** Basic Python and OpenCV knowledge. Familiarity with camera calibration concepts is helpful but not required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source Selection",
    "",
    "Choose your data source:",
    "",
    "- **`synthetic`** (recommended for first run): Generates a small synthetic rig on-the-fly. Fast, no download required.",
    "- **`preset`**: Uses a bundled small dataset (2 cameras, 10 frames). No download required.",
    "- **`zenodo`**: Downloads a larger synthetic dataset from Zenodo (6 cameras, 80 frames). Requires internet connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE = \"synthetic\"  # Options: \"synthetic\", \"preset\", \"zenodo\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports",
    "",
    "We'll import the necessary modules and configure matplotlib for inline plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np",
    "import matplotlib.pyplot as plt",
    "from aquacal.datasets import generate_synthetic_rig, load_example",
    "from aquacal.config.schema import InterfaceParams, DiagnosticsData, CalibrationMetadata",
    "from aquacal.validation.diagnostics import plot_camera_rig",
    "",
    "# Configure matplotlib",
    "plt.rcParams['figure.figsize'] = (10, 6)",
    "plt.rcParams['font.size'] = 10",
    "",
    "print(\"Imports complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Calibration Data",
    "",
    "Now we'll load the calibration scenario based on your data source selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_SOURCE == \"synthetic\":",
    "    # Generate small synthetic rig (2 cameras, 10 frames)",
    "    scenario = generate_synthetic_rig(\"small\")",
    "    print(f\"Generated synthetic scenario: {scenario.name}\")",
    "    print(f\"  Cameras: {len(scenario.intrinsics)}\")",
    "    print(f\"  Frames: {len(scenario.board_poses)}\")",
    "    print(f\"  Description: {scenario.description}\")",
    "elif DATA_SOURCE == \"preset\":",
    "    # Load bundled preset data",
    "    dataset = load_example(\"small\")",
    "    scenario = dataset.ground_truth",
    "    print(f\"Loaded preset dataset: {dataset.name}\")",
    "    print(f\"  Cameras: {len(scenario.intrinsics)}\")",
    "    print(f\"  Frames: {len(scenario.board_poses)}\")",
    "else:  # zenodo",
    "    # Download medium dataset from Zenodo",
    "    dataset = load_example(\"medium\")",
    "    scenario = dataset.ground_truth",
    "    print(f\"Downloaded Zenodo dataset: {dataset.name}\")",
    "    print(f\"  Cameras: {len(scenario.intrinsics)}\")",
    "    print(f\"  Frames: {len(scenario.board_poses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Data",
    "",
    "Let's explore the structure of our calibration scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show camera configuration",
    "camera_names = list(scenario.intrinsics.keys())",
    "print(f\"Camera names: {camera_names}\")",
    "print(f\"\\nBoard configuration:\")",
    "print(f\"  Squares: {scenario.board_config.squares_x} x {scenario.board_config.squares_y}\")",
    "print(f\"  Square size: {scenario.board_config.square_size * 1000:.1f} mm\")",
    "print(f\"  Marker size: {scenario.board_config.marker_size * 1000:.1f} mm\")",
    "print(f\"\\nInterface distances (water surface Z):\")",
    "for cam_name in sorted(scenario.intrinsics.keys()):",
    "    print(f\"  {cam_name}: {scenario.water_zs[cam_name]:.4f} m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Intrinsic Calibration",
    "",
    "For synthetic data, intrinsics are provided as ground truth. For real data, you would run Stage 1 to calibrate intrinsics from in-air videos.",
    "",
    "Let's visualize the intrinsic parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize intrinsic parameters",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))",
    "",
    "cameras = sorted(scenario.intrinsics.keys())",
    "fx_vals = [scenario.intrinsics[cam].K[0, 0] for cam in cameras]",
    "cx_vals = [scenario.intrinsics[cam].K[0, 2] for cam in cameras]",
    "cy_vals = [scenario.intrinsics[cam].K[1, 2] for cam in cameras]",
    "",
    "# Focal lengths",
    "x = np.arange(len(cameras))",
    "ax1.bar(x, fx_vals, color='steelblue', alpha=0.7)",
    "ax1.set_xlabel('Camera')",
    "ax1.set_ylabel('Focal Length (pixels)')",
    "ax1.set_title('Focal Lengths (fx)')",
    "ax1.set_xticks(x)",
    "ax1.set_xticklabels(cameras)",
    "ax1.grid(axis='y', alpha=0.3)",
    "",
    "# Principal points",
    "ax2.scatter(cx_vals, cy_vals, s=100, color='steelblue', alpha=0.7)",
    "for i, cam in enumerate(cameras):",
    "    ax2.annotate(cam, (cx_vals[i], cy_vals[i]), xytext=(5, 5), textcoords='offset points')",
    "ax2.set_xlabel('cx (pixels)')",
    "ax2.set_ylabel('cy (pixels)')",
    "ax2.set_title('Principal Points')",
    "ax2.grid(alpha=0.3)",
    "ax2.axis('equal')",
    "",
    "plt.tight_layout()",
    "plt.show()",
    "plt.close()",
    "",
    "print(\"Intrinsic parameters visualized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Extrinsic Initialization",
    "",
    "Stage 2 estimates initial camera poses using a BFS-based pose graph and pairwise relative pose estimation.",
    "",
    "Let's visualize the camera rig geometry:",
    "",
    "> **Warning:** Insufficient camera overlap can cause disconnected pose graphs. Ensure each camera pair shares at least 5-10 board observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize camera rig in 3D",
    "from aquacal.config.schema import CalibrationResult, CameraCalibration",
    "",
    "# Build temporary CalibrationResult for visualization",
    "cameras_dict = {}",
    "for cam_name, intr in scenario.intrinsics.items():",
    "    cameras_dict[cam_name] = CameraCalibration(",
    "        name=cam_name,",
    "        intrinsics=intr,",
    "        extrinsics=scenario.extrinsics[cam_name],",
    "        water_z=scenario.water_zs[cam_name],",
    "    )",
    "",
    "temp_result = CalibrationResult(",
    "    cameras=cameras_dict,",
    "    interface=InterfaceParams(",
    "        normal=np.array([0.0, 0.0, -1.0]),",
    "        n_air=1.0,",
    "        n_water=1.333",
    "    ),",
    "    board=scenario.board_config,",
    "    diagnostics=DiagnosticsData(",
    "        reprojection_error_rms=0.0,",
    "        reprojection_error_per_camera={},",
    "        validation_3d_error_mean=0.0,",
    "        validation_3d_error_std=0.0",
    "    ),",
    "    metadata=CalibrationMetadata(",
    "        calibration_date='',",
    "        software_version='',",
    "        config_hash='',",
    "        num_frames_used=0,",
    "        num_frames_holdout=0",
    "    )",
    ")",
    "",
    "fig = plot_camera_rig(temp_result, title=\"Stage 2: Camera Rig Geometry (Ground Truth)\")",
    "plt.show()",
    "plt.close()",
    "",
    "print(\"Camera rig geometry visualized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Joint Refractive Optimization",
    "",
    "Stage 3 jointly optimizes:",
    "- Camera extrinsics (rotation + translation)",
    "- Interface distances (water surface Z-coordinate)",
    "- Board poses for all frames",
    "",
    "This is the core optimization that accounts for refraction at the air-water interface.",
    "",
    "> **Warning:** If interface distance doesn't converge, check that initial estimates are within 2-3x of the true value.",
    "",
    "For this tutorial with synthetic data, we're using the ground truth directly. In a real pipeline, you would call the optimization functions from `aquacal.calibration.pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For synthetic data, we already have the optimized result",
    "# In a real pipeline, you would run:",
    "#   from aquacal.calibration.interface_estimation import optimize_interface",
    "#   extrinsics, distances, poses, rms = optimize_interface(...)",
    "",
    "# Show the ground truth interface parameters",
    "water_z = list(scenario.water_zs.values())[0]",
    "print(f\"Water surface Z-coordinate: {water_z:.4f} m\")",
    "print(\"\\nCamera positions in world frame:\")",
    "for cam_name in sorted(scenario.extrinsics.keys()):",
    "    C = scenario.extrinsics[cam_name].C",
    "    h_c = water_z - C[2]  # camera-to-water vertical distance",
    "    print(f\"  {cam_name}: C = [{C[0]:.3f}, {C[1]:.3f}, {C[2]:.3f}]  h_c = {h_c:.4f} m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics\n",
    "\n",
    "Now we run the actual calibration pipeline (Stages 2 and 3) on the loaded data,\n",
    "then inspect the quality of the result using several diagnostic visualizations.\n",
    "\n",
    "**Reprojection error** measures how well the calibrated model predicts the observed corner\n",
    "positions. Values below 1 px indicate accurate calibration.\n",
    "\n",
    "> **Note:** The calibration below uses Stages 2-3 only; Stage 4 intrinsic refinement is\n",
    "> shown separately afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic detections and run calibration (Stages 2-3)\n",
    "from aquacal.core.board import BoardGeometry\n",
    "from aquacal.calibration.extrinsics import build_pose_graph, estimate_extrinsics\n",
    "from aquacal.calibration.interface_estimation import optimize_interface\n",
    "from aquacal.config.schema import (\n",
    "    CalibrationResult, CameraCalibration, DiagnosticsData, CalibrationMetadata\n",
    ")\n",
    "from aquacal.validation.reprojection import compute_reprojection_errors\n",
    "from tests.synthetic.ground_truth import generate_synthetic_detections\n",
    "\n",
    "board = BoardGeometry(scenario.board_config)\n",
    "interface_normal = np.array([0.0, 0.0, -1.0], dtype=np.float64)\n",
    "reference_camera = camera_names[0]\n",
    "\n",
    "# Generate synthetic detections from ground truth scenario\n",
    "print(\"Generating synthetic detections...\")\n",
    "detections = generate_synthetic_detections(\n",
    "    intrinsics=scenario.intrinsics,\n",
    "    extrinsics=scenario.extrinsics,\n",
    "    water_zs=scenario.water_zs,\n",
    "    board=board,\n",
    "    board_poses=scenario.board_poses,\n",
    "    noise_std=scenario.noise_std,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# Stage 2: Extrinsic initialization\n",
    "print(\"Stage 2: Extrinsic initialization...\")\n",
    "pose_graph = build_pose_graph(detections, min_cameras=2)\n",
    "initial_extrinsics = estimate_extrinsics(\n",
    "    pose_graph, scenario.intrinsics, board, reference_camera\n",
    ")\n",
    "\n",
    "# Stage 3: Joint refractive optimization\n",
    "print(\"Stage 3: Joint refractive optimization...\")\n",
    "opt_extrinsics, opt_distances, opt_poses, rms = optimize_interface(\n",
    "    detections=detections,\n",
    "    intrinsics=scenario.intrinsics,\n",
    "    initial_extrinsics=initial_extrinsics,\n",
    "    board=board,\n",
    "    reference_camera=reference_camera,\n",
    "    interface_normal=interface_normal,\n",
    "    n_air=1.0,\n",
    "    n_water=1.333,\n",
    "    loss=\"huber\",\n",
    "    loss_scale=1.0,\n",
    "    min_corners=4,\n",
    ")\n",
    "\n",
    "# Build CalibrationResult with per-camera RMS\n",
    "diag_cameras = {}\n",
    "per_camera_rms = {}\n",
    "for cam_name in scenario.intrinsics:\n",
    "    diag_cameras[cam_name] = CameraCalibration(\n",
    "        name=cam_name,\n",
    "        intrinsics=scenario.intrinsics[cam_name],\n",
    "        extrinsics=opt_extrinsics[cam_name],\n",
    "        water_z=opt_distances[cam_name],\n",
    "    )\n",
    "    cam_errors = compute_reprojection_errors(\n",
    "        calibration=diag_cameras[cam_name],\n",
    "        interface_params=InterfaceParams(normal=interface_normal, n_air=1.0, n_water=1.333),\n",
    "        detections=detections,\n",
    "        board=board,\n",
    "    )\n",
    "    per_camera_rms[cam_name] = np.sqrt(np.mean(cam_errors**2))\n",
    "\n",
    "interface_params = InterfaceParams(normal=interface_normal, n_air=1.0, n_water=1.333)\n",
    "diag_result = CalibrationResult(\n",
    "    cameras=diag_cameras,\n",
    "    interface=interface_params,\n",
    "    board=scenario.board_config,\n",
    "    diagnostics=DiagnosticsData(\n",
    "        reprojection_error_rms=rms,\n",
    "        reprojection_error_per_camera=per_camera_rms,\n",
    "        validation_3d_error_mean=0.0,\n",
    "        validation_3d_error_std=0.0,\n",
    "    ),\n",
    "    metadata=CalibrationMetadata(\n",
    "        calibration_date=\"synthetic\",\n",
    "        software_version=\"test\",\n",
    "        config_hash=\"synthetic\",\n",
    "        num_frames_used=len(opt_poses),\n",
    "        num_frames_holdout=0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f\"\\nCalibration complete!\")\n",
    "print(f\"  Overall RMS: {diag_result.diagnostics.reprojection_error_rms:.3f} px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-Camera Reprojection Error\n",
    "\n",
    "A bar chart of per-camera RMS errors quickly reveals whether any camera is performing\n",
    "worse than the others. Cameras with high error often have poor intrinsic calibration or\n",
    "insufficient board observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-camera RMS error bar chart\n",
    "cam_names_sorted = sorted(diag_result.cameras.keys())\n",
    "rms_values = [\n",
    "    diag_result.diagnostics.reprojection_error_per_camera[cam] for cam in cam_names_sorted\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.bar(cam_names_sorted, rms_values, color=\"steelblue\", alpha=0.8)\n",
    "ax.axhline(\n",
    "    diag_result.diagnostics.reprojection_error_rms,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Overall RMS: {diag_result.diagnostics.reprojection_error_rms:.3f} px\",\n",
    ")\n",
    "ax.set_xlabel(\"Camera\")\n",
    "ax.set_ylabel(\"RMS Reprojection Error (px)\")\n",
    "ax.set_title(\"Per-Camera Reprojection Error\")\n",
    "ax.legend()\n",
    "ax.grid(axis=\"y\", alpha=0.3)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"Cameras with error > 2x the average may need re-calibration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reprojection Error Distribution\n",
    "\n",
    "The histogram shows the overall distribution of per-corner errors across all cameras\n",
    "and frames. A well-calibrated rig produces a tight distribution centered near zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all reprojection error magnitudes\n",
    "all_errors = []\n",
    "for cam_name in cam_names_sorted:\n",
    "    cam = diag_result.cameras[cam_name]\n",
    "    errors = compute_reprojection_errors(\n",
    "        calibration=cam,\n",
    "        interface_params=diag_result.interface,\n",
    "        detections=detections,\n",
    "        board=board,\n",
    "    )\n",
    "    all_errors.extend(np.linalg.norm(errors, axis=1))\n",
    "\n",
    "# Histogram of error distribution\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.hist(all_errors, bins=30, color=\"steelblue\", alpha=0.7, edgecolor=\"black\")\n",
    "ax.axvline(\n",
    "    np.mean(all_errors),\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Mean: {np.mean(all_errors):.3f} px\",\n",
    ")\n",
    "ax.set_xlabel(\"Reprojection Error (px)\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_title(\"Reprojection Error Distribution (All Cameras)\")\n",
    "ax.legend()\n",
    "ax.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(f\"Error statistics:\")\n",
    "print(f\"  Mean:            {np.mean(all_errors):.3f} px\")\n",
    "print(f\"  Median:          {np.median(all_errors):.3f} px\")\n",
    "print(f\"  95th percentile: {np.percentile(all_errors, 95):.3f} px\")\n",
    "print(f\"  Max:             {np.max(all_errors):.3f} px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interface Distance Recovery\n",
    "\n",
    "The water surface Z-coordinate (`interface_distance`) is the key refractive parameter.\n",
    "Comparing estimated values to ground truth tells you how well Stage 3 converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare estimated interface distances to ground truth\n",
    "estimated_distances = [diag_result.cameras[cam].water_z for cam in cam_names_sorted]\n",
    "gt_distances = [scenario.water_zs[cam] for cam in cam_names_sorted]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "x = np.arange(len(cam_names_sorted))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width / 2, estimated_distances, width, label=\"Estimated\", color=\"steelblue\", alpha=0.8)\n",
    "ax.bar(x + width / 2, gt_distances, width, label=\"Ground Truth\", color=\"orange\", alpha=0.8)\n",
    "\n",
    "ax.set_xlabel(\"Camera\")\n",
    "ax.set_ylabel(\"Interface Distance (m)\")\n",
    "ax.set_title(\"Interface Distance Recovery\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(cam_names_sorted, rotation=45, ha=\"right\")\n",
    "ax.legend()\n",
    "ax.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "mean_err = np.mean([abs(e - g) for e, g in zip(estimated_distances, gt_distances)])\n",
    "print(f\"Mean absolute interface distance error: {mean_err * 1000:.2f} mm\")\n",
    "print()\n",
    "print(\"If estimated and ground-truth bars differ significantly, check that the initial\")\n",
    "print(\"interface distance estimate (initial_water_zs) is within 2-3x of the true value.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Reconstruction Error\n",
    "\n",
    "Reprojection error measures 2D fit quality, but 3D reconstruction error is the ultimate\n",
    "accuracy metric. We triangulate board corners from multiple cameras and compare the\n",
    "recovered inter-corner distances to the known ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aquacal.validation.reconstruction import compute_3d_distance_errors\n",
    "\n",
    "dist_errors = compute_3d_distance_errors(\n",
    "    calibration=diag_result,\n",
    "    detections=detections,\n",
    "    board=board,\n",
    "    include_per_pair=False,\n",
    "    include_spatial=True,\n",
    ")\n",
    "\n",
    "print(\"3D Reconstruction Quality:\")\n",
    "print(f\"  Signed mean error: {dist_errors.signed_mean * 1000:.3f} mm\")\n",
    "print(f\"  RMSE:              {dist_errors.rmse * 1000:.3f} mm\")\n",
    "print(f\"  Comparisons:       {dist_errors.num_comparisons}\")\n",
    "\n",
    "# Histogram of distance errors\n",
    "if dist_errors.spatial is not None:\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.hist(\n",
    "        dist_errors.spatial.signed_errors * 1000,\n",
    "        bins=30,\n",
    "        color=\"steelblue\",\n",
    "        alpha=0.7,\n",
    "        edgecolor=\"black\",\n",
    "    )\n",
    "    ax.axvline(0, color=\"black\", linestyle=\"--\", alpha=0.5)\n",
    "    ax.axvline(\n",
    "        dist_errors.signed_mean * 1000,\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Mean: {dist_errors.signed_mean * 1000:.2f} mm\",\n",
    "    )\n",
    "    ax.set_xlabel(\"Signed Distance Error (mm)\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.set_title(\"3D Reconstruction Error Distribution\")\n",
    "    ax.legend()\n",
    "    ax.grid(axis=\"y\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Issues Checklist\n",
    "\n",
    "| Symptom | Likely Cause | Fix |\n",
    "|---------|-------------|-----|\n",
    "| High error for one camera | Poor intrinsic calibration | Re-calibrate intrinsics with more frames, check for motion blur |\n",
    "| High error in image corners | Distortion model insufficient | Try rational model (8 coefficients) |\n",
    "| Interface distance not converging | Initial estimate too far from truth | Provide better `initial_water_zs` in config |\n",
    "| Interface distances differ between cameras | Degenerate board poses | Ensure board is visible at varied angles and depths |\n",
    "| High 3D reconstruction error | Systematic bias | Check that `n_water` is correct for your water type |\n",
    "| Reprojection < 1px but 3D error high | Overfitting to 2D | Verify interface distance initialization, add validation frames |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4: Optional Intrinsic Refinement",
    "",
    "Stage 4 optionally refines per-camera focal lengths (fx, fy) and principal points (cx, cy) alongside extrinsics and interface distances.",
    "",
    "**When to enable:** Only after Stage 3 converges reliably. Distortion coefficients are NOT refined.",
    "",
    "For synthetic data with perfect intrinsics, this stage would provide minimal benefit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 4 is optional and disabled by default",
    "# Enable with refine_intrinsics=True in CalibrationConfig",
    "print(\"Stage 4 skipped (refine_intrinsics=False)\")",
    "print(\"Recommended for real hardware where intrinsics may have residual errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation",
    "",
    "For synthetic data, we can validate by comparing the calibration result to ground truth. For real data, validation uses held-out frames and 3D reconstruction error.",
    "",
    "Key metrics:",
    "- **Reprojection RMS**: How well the calibration predicts observed corner positions (pixels)",
    "- **3D reconstruction error**: How accurately pairwise 3D distances are recovered (meters or mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this synthetic example, reprojection error would be near-zero",
    "# (we're using ground truth parameters)",
    "print(\"Validation metrics (ground truth):\")",
    "print(\"  Reprojection RMS: ~0.0 pixels (perfect calibration)\")",
    "print(\"  3D reconstruction error: ~0.0 mm (perfect calibration)\")",
    "print(\"\\nFor real calibration pipelines:\")",
    "print(\"  - Typical reprojection RMS: 0.3-1.0 pixels\")",
    "print(\"  - Typical 3D error: 1-3 mm for ~30mm square size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Results",
    "",
    "AquaCal provides utilities to save and load calibration results in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save calibration result",
    "from aquacal.io.serialization import save_calibration, load_calibration",
    "",
    "# In a real pipeline:",
    "# save_calibration(result, \"output/calibration.json\")",
    "# loaded_result = load_calibration(\"output/calibration.json\")",
    "",
    "print(\"Calibration results can be saved to JSON for later use.\")",
    "print(\"See aquacal.io.serialization.save_calibration() and load_calibration().\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned how to:\n",
    "\n",
    "1. Load calibration data (synthetic, preset, or Zenodo)\n",
    "2. Understand the calibration scenario structure\n",
    "3. Visualize intrinsic parameters\n",
    "4. Run and understand the four-stage calibration pipeline:\n",
    "   - **Stage 1**: Intrinsic calibration (in-air)\n",
    "   - **Stage 2**: Extrinsic initialization via pose graph\n",
    "   - **Stage 3**: Joint refractive optimization\n",
    "   - **Stage 4**: Optional intrinsic refinement\n",
    "5. Diagnose calibration quality with reprojection and 3D error analysis\n",
    "6. Save and load calibration results\n",
    "\n",
    "**Next:** Explore [why refractive calibration matters](02_synthetic_validation.ipynb) with\n",
    "controlled experiments comparing refractive vs non-refractive models.\n",
    "\n",
    "- [User Guide](../guide/index.md): Comprehensive documentation on calibration theory and best practices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
