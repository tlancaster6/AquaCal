---
phase: 10-documentation-audit
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - .planning/phases/10-documentation-audit/10-01-AUDIT-REPORT.md
autonomous: true
must_haves:
  truths:
    - "All public API docstrings have been audited for consistency, accuracy, and Google-style format"
    - "All Sphinx documentation source files have been audited for accuracy, formatting, and completeness"
    - "Spelling of 'auxiliary' has been checked across all docs and code"
    - "README has been audited for accuracy and alignment with current features"
    - "An audit findings report exists that the user can review before fixes are applied"
  artifacts:
    - path: ".planning/phases/10-documentation-audit/10-01-AUDIT-REPORT.md"
      provides: "Categorized audit findings with proposed fixes"
  key_links: []
---

<objective>
Audit all docstrings and Sphinx documentation for quality, consistency, accuracy, and formatting. Produce a structured findings report for user review.

Purpose: The audit report is the prerequisite for all documentation fixes. The user reviews findings and approves which fixes to apply before any changes are made (per locked decision).
Output: `.planning/phases/10-documentation-audit/10-01-AUDIT-REPORT.md`
</objective>

<execution_context>
@C:/Users/tucke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/tucke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/10-documentation-audit/10-CONTEXT.md
@.planning/architecture.md
@src/aquacal/config/schema.py
@src/aquacal/cli.py
@docs/index.md
@docs/overview.md
@docs/guide/index.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Audit docstrings across public API and key internal modules</name>
  <files>.planning/phases/10-documentation-audit/10-01-AUDIT-REPORT.md</files>
  <action>
Systematically audit all docstrings in these modules (public API + key internals):

**Public API modules (every public class/function/method):**
- `src/aquacal/__init__.py` (top-level exports)
- `src/aquacal/config/schema.py` (all dataclasses and types)
- `src/aquacal/core/camera.py` (Camera, FisheyeCamera, create_camera)
- `src/aquacal/core/board.py` (board geometry)
- `src/aquacal/core/interface_model.py` (InterfaceModel)
- `src/aquacal/core/refractive_geometry.py` (projection functions)
- `src/aquacal/calibration/pipeline.py` (run_calibration, load_config)
- `src/aquacal/io/serialization.py` (load_calibration, save_calibration)
- `src/aquacal/io/detection.py` (detection functions)
- `src/aquacal/io/video.py` (VideoSet)
- `src/aquacal/io/frameset.py` (FrameSet protocol)
- `src/aquacal/io/images.py` (image loading)
- `src/aquacal/triangulation/triangulate.py` (triangulation)
- `src/aquacal/validation/reprojection.py` (reprojection errors)
- `src/aquacal/validation/reconstruction.py` (3D reconstruction metrics)
- `src/aquacal/validation/diagnostics.py` (diagnostic reports)
- `src/aquacal/validation/comparison.py` (cross-run comparison)
- `src/aquacal/datasets/` (all public functions)
- `src/aquacal/utils/transforms.py` (rotation/pose utilities)

**Key internal modules:**
- `src/aquacal/calibration/_optim_common.py` (optimization backbone)
- `src/aquacal/calibration/intrinsics.py` (Stage 1)
- `src/aquacal/calibration/extrinsics.py` (Stage 2)
- `src/aquacal/calibration/interface_estimation.py` (Stage 3)
- `src/aquacal/calibration/refinement.py` (Stage 4)
- `src/aquacal/cli.py` (CLI)

**For each module, check:**
1. Module-level docstring exists and is accurate
2. All public functions/methods have docstrings
3. Google-style format (Args, Returns, Raises sections)
4. Consistent tense (imperative for first line: "Compute..." not "Computes...")
5. Type hints present on parameters and return types
6. NDArray shapes documented in docstrings where applicable
7. Parameter descriptions are accurate (match actual behavior)
8. No stale/outdated references (e.g., old parameter names, removed features)
9. Units documented where relevant (meters, radians, etc.)

**Also check:**
- Spelling of "auxiliary" across all .py and .md files (grep for "auxill" to catch misspellings)
- Inconsistent terminology: "calibration target" vs "board" vs "ChArUco board" — document which terms are used where
- README.md accuracy: badges, feature list, quick start, installation instructions

Write findings to the first half of the audit report file, organized by severity:
- **Errors**: Factually wrong, misleading, or broken references
- **Inconsistencies**: Style/format/terminology differences
- **Gaps**: Missing docstrings, missing parameter docs, missing sections
- **Terminology**: Inconsistent term usage with proposed standardization
  </action>
  <verify>The audit report file exists and contains categorized findings for docstrings, spelling, terminology, and README.</verify>
  <done>All public API and key internal module docstrings audited; spelling of "auxiliary" checked; terminology inconsistencies catalogued; README audited.</done>
</task>

<task type="auto">
  <name>Task 2: Audit Sphinx documentation source files</name>
  <files>.planning/phases/10-documentation-audit/10-01-AUDIT-REPORT.md</files>
  <action>
Audit all Sphinx documentation source files for accuracy, formatting, and completeness:

**Files to audit:**
- `docs/index.md` — Landing page, badges, quick start
- `docs/overview.md` — Project overview
- `docs/guide/index.md` — User guide index
- `docs/guide/refractive_geometry.md` — Refractive geometry theory
- `docs/guide/coordinates.md` — Coordinate conventions
- `docs/guide/optimizer.md` — Optimizer pipeline
- `docs/contributing.md` — Contribution guide
- `docs/changelog.md` — Changelog
- `docs/api/index.rst` — API reference index
- `docs/api/*.rst` — All API reference pages (check autodoc directives match actual module structure)
- `docs/tutorials/index.md` — Tutorial index
- `docs/conf.py` — Sphinx config (check extensions, theme settings)
- Jupyter notebooks in `docs/tutorials/` — Check that markdown cells reference correct API, parameter names

**For each file, check:**
1. Technical accuracy (do descriptions match actual code behavior?)
2. Cross-references work (links to other pages, API references)
3. Code examples are correct and up-to-date
4. Consistent formatting (headings, code blocks, admonitions)
5. No references to `interface_distance` that will need updating (catalogue for Plan 02)
6. Parameter names match current code
7. Completeness — what a new user would need vs. what exists

**Identify documentation gaps** by comparing existing docs against new user needs:
- Is there a CLI usage guide? (No — this is a pending todo)
- Is there camera model documentation? (No — pending todo)
- Is there a troubleshooting section? (No — pending todo)
- Is there a glossary? (No — pending todo)
- Is there a Background/Concepts section for non-CV engineers? (Check)
- Are allowed camera combinations documented? (No — pending todo)

Append Sphinx findings to the audit report, same severity categories. Include a section listing all `interface_distance` references that Plan 02 will update. Include a section identifying documentation gaps (what's missing for new users).
  </action>
  <verify>The audit report contains Sphinx documentation findings, interface_distance reference catalogue, and gap analysis.</verify>
  <done>All Sphinx source files audited; interface_distance references catalogued; documentation gaps identified; findings appended to audit report.</done>
</task>

</tasks>

<verification>
- `.planning/phases/10-documentation-audit/10-01-AUDIT-REPORT.md` exists and is well-structured
- Report contains: docstring findings, Sphinx findings, spelling check results, terminology analysis, README audit, interface_distance catalogue, gap analysis
- Findings are categorized by severity (Errors, Inconsistencies, Gaps, Terminology)
- Each finding has enough detail for the user to evaluate and approve/reject
</verification>

<success_criteria>
- Comprehensive audit report produced covering all public API docstrings, key internal modules, and all Sphinx documentation
- No files modified except the report — changes come in later plans after user review
- Spelling of "auxiliary" verified across entire codebase
- Documentation gaps clearly identified with specific recommendations
</success_criteria>

<output>
After completion, create `.planning/phases/10-documentation-audit/10-01-SUMMARY.md`
</output>
