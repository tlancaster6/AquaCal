---
phase: 06-interactive-tutorials
plan: 03
type: execute
wave: 2
depends_on: ["06-02"]
files_modified:
  - docs/tutorials/01_full_pipeline.ipynb
autonomous: true

must_haves:
  truths:
    - "User can run the full pipeline notebook end-to-end using preset data without manual preparation"
    - "Notebook demonstrates config creation, intrinsic calibration, extrinsic estimation, joint optimization, and validation"
    - "Data source toggle at top lets user switch between synthetic, preset, and zenodo"
    - "Notebook includes rich visualizations: 3D rig plot, reprojection error plots, before/after comparisons"
    - "Failure modes are explained via inline warning callouts where relevant"
    - "Google Colab badge is present for cloud execution"
  artifacts:
    - path: "docs/tutorials/01_full_pipeline.ipynb"
      provides: "End-to-end calibration pipeline tutorial"
  key_links:
    - from: "docs/tutorials/01_full_pipeline.ipynb"
      to: "aquacal.datasets"
      via: "load_example and generate_synthetic_rig imports"
      pattern: "from aquacal"
    - from: "docs/tutorials/01_full_pipeline.ipynb"
      to: "aquacal.calibration.pipeline"
      via: "run_calibration or stage-by-stage API calls"
      pattern: "calibrat"
---

<objective>
Create the full pipeline tutorial notebook demonstrating end-to-end calibration from data loading through validation, with rich visualizations and inline explanations.

Purpose: Satisfy NB-01, TUT-01, TUT-02 -- users can follow a getting-started tutorial from data to calibration result, covering all pipeline stages.
Output: Pre-executed `docs/tutorials/01_full_pipeline.ipynb` with committed outputs.
</objective>

<execution_context>
@C:/Users/tucke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/tucke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-interactive-tutorials/06-02-SUMMARY.md
@src/aquacal/datasets/__init__.py
@src/aquacal/calibration/pipeline.py
@src/aquacal/config/schema.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create full pipeline tutorial notebook</name>
  <files>docs/tutorials/01_full_pipeline.ipynb</files>
  <action>
    Create a Jupyter notebook `docs/tutorials/01_full_pipeline.ipynb` with pre-executed outputs. The notebook must be self-contained and work end-to-end with preset data.

    **Cell structure:**

    1. **Title + Colab badge** (markdown):
       - Title: "Full Pipeline Tutorial"
       - Colab badge: `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tlancaster6/AquaCal/blob/main/docs/tutorials/01_full_pipeline.ipynb)`
       - Brief intro: what this tutorial covers (end-to-end calibration of a multi-camera rig)
       - Audience note: assumes Python + OpenCV basics

    2. **Data source toggle** (code):
       ```python
       DATA_SOURCE = "synthetic"  # Options: "synthetic", "preset", "zenodo"
       ```
       With markdown explanation of each option above the cell.

    3. **Setup + imports** (code):
       - Import aquacal modules (datasets, pipeline stages, visualization helpers)
       - Import numpy, matplotlib
       - Set matplotlib inline mode
       - Load data based on DATA_SOURCE selection

    4. **Understanding the data** (markdown + code):
       - Show scenario structure: cameras, board, detections
       - Print camera names, frame count, board dimensions
       - Visualize a sample detection (if images available) or show detection statistics

    5. **Stage 1: Intrinsic Calibration** (markdown + code):
       - Explain what intrinsics are and why in-air calibration matters
       - For synthetic/preset: intrinsics are provided (show them)
       - For real data: would call Stage 1
       - Visualize intrinsic parameters (focal lengths, principal points as bar charts)

    6. **Stage 2: Extrinsic Initialization** (markdown + code):
       - Explain BFS pose graph and initial extrinsic estimation
       - Run or show extrinsic initialization
       - **3D camera rig visualization**: plot camera positions and orientations in 3D using matplotlib
       - **Warning callout**: "Insufficient camera overlap can cause disconnected pose graphs. Ensure each camera pair shares at least 5-10 board observations."

    7. **Stage 3: Joint Refractive Optimization** (markdown + code):
       - Explain what's being optimized (extrinsics + interface distances + board poses)
       - Run optimization
       - Show convergence: cost vs iteration
       - Show before/after reprojection errors
       - **Warning callout**: "If interface distance doesn't converge, check that initial estimates are within 2-3x of the true value."

    8. **Stage 4: Optional Intrinsic Refinement** (markdown + code):
       - Explain when this is useful
       - Show how to enable it
       - Compare results with and without

    9. **Validation** (markdown + code):
       - Show holdout reprojection errors
       - Show per-camera error breakdown
       - Show 3D reconstruction error (if synthetic, compare to ground truth)

    10. **Saving and Loading Results** (markdown + code):
        - Demonstrate save_calibration / load_calibration
        - Show how to use CalibrationResult.project() and .back_project()

    11. **Summary** (markdown):
        - Recap what was covered
        - Links to diagnostics notebook and synthetic validation notebook

    **Key requirements:**
    - Use `generate_synthetic_rig("small")` for the default DATA_SOURCE="synthetic" path (fast, no download)
    - All cells must execute without error
    - Close matplotlib figures after display with `plt.close()` to manage memory
    - Include rich visualizations per user decision: 3D rig plots, error bar charts, convergence curves
    - Failure mode warnings as inline `:::{warning}` or `> **Warning:**` callouts in markdown cells
    - Pre-execute the notebook and commit with outputs (nbsphinx_execute = "never")

    **To create pre-executed notebook:**
    - Build the notebook as a Python script first, then convert to .ipynb format
    - OR create the .ipynb JSON directly with cell outputs included
    - The notebook must have `metadata.kernelspec` set to Python 3
    - Cell outputs should include text outputs and matplotlib PNG images (base64-encoded in output cells)

    **Practical approach for pre-execution:**
    - Create the notebook structure as .ipynb JSON
    - Execute it via `jupyter nbconvert --to notebook --execute` if jupyter is available
    - OR run the code cells manually and capture outputs into the notebook JSON
    - If execution environment is limited, create notebook with empty outputs and note in the summary that outputs need manual execution
  </action>
  <verify>
    ```bash
    python -c "import json; nb=json.load(open('docs/tutorials/01_full_pipeline.ipynb')); print(f'Cells: {len(nb[\"cells\"])}'); print(f'Has outputs: {any(c.get(\"outputs\") for c in nb[\"cells\"] if c[\"cell_type\"]==\"code\")}')"
    ```
    Notebook exists with multiple cells. Ideally has pre-executed outputs.
  </verify>
  <done>Full pipeline tutorial notebook exists at docs/tutorials/01_full_pipeline.ipynb with title, Colab badge, data source toggle, all 4 pipeline stages demonstrated, rich visualizations, failure mode callouts, and pre-executed outputs.</done>
</task>

</tasks>

<verification>
```bash
# Notebook is valid JSON
python -c "import json; json.load(open('docs/tutorials/01_full_pipeline.ipynb')); print('Valid')"

# Has Colab badge
python -c "import json; nb=json.load(open('docs/tutorials/01_full_pipeline.ipynb')); cells=nb['cells']; print('Colab' in cells[0]['source'][0] if cells else 'No cells')"

# Sphinx build picks it up (may need plan 02 complete first)
cd docs && python -m sphinx -b html . _build/html 2>&1 | tail -5
```
</verification>

<success_criteria>
- Notebook exists at docs/tutorials/01_full_pipeline.ipynb
- Contains Colab badge, data source toggle, all 4 pipeline stages
- Includes 3D camera rig visualization, reprojection error plots, convergence curves
- Contains inline warning callouts for failure modes
- Executes end-to-end with synthetic data (or has structure ready for execution)
- Integrated into Sphinx docs via nbsphinx
</success_criteria>

<output>
After completion, create `.planning/phases/06-interactive-tutorials/06-03-SUMMARY.md`
</output>
